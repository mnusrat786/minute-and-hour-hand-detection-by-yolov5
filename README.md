# â° Minute and Hour Hand Detection - YOLOv5
A **YOLOv5-based model** for detecting the **minute and hour hands of a watch** using object detection techniques.

---

## ğŸ“Œ Setup Instructions

### ğŸ”¹ Step 1: Clone the Repository and Install Dependencies
First, download the repository and install the required dependencies:
```bash
git clone https://github.com/mnusrat786/minute-and-hour-hand-detection-by-yolov5.git
cd minute-and-hour-hand-detection-by-yolov5
pip install -r requirements.txt
```

### ğŸ”¹ Step 2: Install YOLOv5
We use **Ultralytics' YOLOv5**. Clone and install it:
```bash
git clone https://github.com/ultralytics/yolov5
cd yolov5
pip install -r requirements.txt
cd ..
```

---

## ğŸ“Œ Dataset Structure

### ğŸ”¹ Step 1: Dataset Organization
Your dataset is stored in `data/` and follows this structure:
```bash
data/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/          # All watch images with minute and hour hands
â”‚   â”‚   â”œâ”€â”€ train/       # Training images
â”‚   â”‚   â”œâ”€â”€ val/         # Validation images
â”‚   â”œâ”€â”€ labels/          # YOLO annotation files
â”‚   â”‚   â”œâ”€â”€ train/       # Training labels
â”‚   â”‚   â”œâ”€â”€ val/         # Validation labels
â”‚   â”œâ”€â”€ dataset.yaml     # YOLOv5 dataset config
```

Ensure your dataset has:
- **Images stored inside `images/train/` and `images/val/`**
- **Labels (annotations) stored inside `labels/train/` and `labels/val/`**
- **A valid `dataset.yaml` file defining the class names (`Minutes` and `Hours`)**

---

## ğŸ“Œ Splitting the Dataset

### ğŸ”¹ Step 1: Run the Dataset Split Script
To split the dataset into training and validation sets, use the provided script:
```bash
python split_dataset.py
```
This will automatically organize images and annotations into `train/` and `val/` folders.

---

## ğŸ“Œ Training the YOLOv5 Model and Running Inference

### ğŸ”¹ Step 1: Train the YOLOv5 Model
To train YOLOv5 on your dataset, run:
```bash
python yolov5/train.py --img 640 --batch 16 --epochs 50 --data data/dataset/dataset.yaml --weights yolov5s.pt
```
- `--img 640` â†’ Image size (YOLOv5 default is 640x640)  
- `--batch 16` â†’ Batch size for training  
- `--epochs 50` â†’ Number of training epochs  
- `--data data/dataset/dataset.yaml` â†’ Dataset configuration file  
- `--weights yolov5s.pt` â†’ Pretrained YOLOv5 model  

### ğŸ”¹ Step 2: Run Detection on an Image
Once the model is trained, run inference to **detect the minute and hour hands** on new images:
```bash
python yolov5/detect.py --weights yolov5/runs/train/exp/weights/best.pt --source path/to/your/test/image.jpg
```
Replace `path/to/your/test/image.jpg` with the actual image path.

### ğŸ”¹ Step 3: Run Detection on a Video
To detect the minute and hour hands in a video, use:
```bash
python yolov5/detect.py --weights yolov5/runs/train/exp/weights/best.pt --source path/to/your/video.mp4
```

---

## ğŸ“Œ Model Results and Trained Weights

After training, your results and weights will be stored in:
```bash
yolov5/runs/train/exp/
â”œâ”€â”€ weights/       # Best trained model
â”œâ”€â”€ labels/        # Detection results
â”œâ”€â”€ results.png    # YOLOv5 training performance graph
```

The final trained model will be located at:
```bash
yolov5/runs/train/exp/weights/best.pt
```

---

## ğŸ“Œ Contributors & Issues

### ğŸ”¹ Contribute to the Project
If you want to improve the project, feel free to fork the repository and submit a pull request.

### ğŸ”¹ Report Issues
If you find any issues, please **open a GitHub issue** describing the problem.

---

## ğŸ“Œ References

### ğŸ”¹ External Resources
- [YOLOv5 Official Repository](https://github.com/ultralytics/yolov5)  
- [LabelImg (For Data Annotation)](https://github.com/heartexlabs/labelImg)  
